{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Databricks API\n",
    "\n",
    "**What is Databricks API?**\n",
    "- A REST-based interface to interact programmatically with Databricks workspace.\n",
    "- Automates workflows, manages clusters, runs jobs, and retrieves data insights.\n",
    "\n",
    "**Use Cases:**\n",
    "- Automating job execution.\n",
    "- Managing Databricks resources.\n",
    "- Integrating with external systems.\n",
    "\n",
    "**Key Components:**\n",
    "- Authentication.\n",
    "- REST API endpoints.\n",
    "- Access tokens for security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token configured successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Store token in environment variable for security\n",
    "databricks_url = \"https://adb-1420859118153884.4.azuredatabricks.net\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"dapi75a302e8520c3953a3d3002d0527ee2e\"\n",
    "\n",
    "# Retrieve token and use in API calls\n",
    "databricks_token = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "headers = {\"Authorization\": f\"Bearer {databricks_token}\"}\n",
    "print(\"Token configured successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Workspace Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling:  https://adb-1420859118153884.4.azuredatabricks.net/api/2.0/workspace/list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objects': [{'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/Extract Data',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734243890988,\n",
       "   'modified_at': 1734329594855,\n",
       "   'object_id': 846899863485469,\n",
       "   'resource_id': '846899863485469'},\n",
       "  {'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/pyspark-join-df',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734002990081,\n",
       "   'modified_at': 1734066860587,\n",
       "   'object_id': 1648461507245785,\n",
       "   'resource_id': '1648461507245785'},\n",
       "  {'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/pyspark-analytics',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734060767426,\n",
       "   'modified_at': 1734244342169,\n",
       "   'object_id': 2110172399548968,\n",
       "   'resource_id': '2110172399548968'},\n",
       "  {'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/PySpark-Broadcast-Join',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734060777993,\n",
       "   'modified_at': 1734070675297,\n",
       "   'object_id': 2110172399548995,\n",
       "   'resource_id': '2110172399548995'},\n",
       "  {'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/Databricks-Spark',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734062867936,\n",
       "   'modified_at': 1734075395369,\n",
       "   'object_id': 2110172399549011,\n",
       "   'resource_id': '2110172399549011'},\n",
       "  {'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/Delta-Lake',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734062904765,\n",
       "   'modified_at': 1734084005976,\n",
       "   'object_id': 2110172399549052,\n",
       "   'resource_id': '2110172399549052'},\n",
       "  {'object_type': 'NOTEBOOK',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/Extract-Data-Task1',\n",
       "   'language': 'PYTHON',\n",
       "   'created_at': 1734253477843,\n",
       "   'modified_at': 1734259447545,\n",
       "   'object_id': 2643742194010736,\n",
       "   'resource_id': '2643742194010736'},\n",
       "  {'object_type': 'DIRECTORY',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/spark-ui',\n",
       "   'object_id': 3901265364172563,\n",
       "   'resource_id': '3901265364172563'},\n",
       "  {'object_type': 'DIRECTORY',\n",
       "   'path': '/Users/pankaj.py2@outlook.com/Demo',\n",
       "   'object_id': 4441295839102749,\n",
       "   'resource_id': '4441295839102749'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Request URI to List the Notebooks\n",
    "url = f\"{databricks_url}/api/2.0/workspace/list\"\n",
    "\n",
    "print(\"Calling: \", url)\n",
    "\n",
    "data = {\n",
    "    \"path\": \"/Users/pankaj.py2@outlook.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, data=json.dumps(data))\n",
    "response_json = response.json()\n",
    "display(response_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Job with cluster configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID: 561370898228136\n"
     ]
    }
   ],
   "source": [
    "# Create a new job\n",
    "job_payload = {\n",
    "    \"name\": \"ETL-SQl-to-DL\",\n",
    "    \"new_cluster\": {\n",
    "        \"num_workers\": 0,\n",
    "        \"spark_version\": \"13.3.x-scala2.12\",\n",
    "        \"spark_conf\": {\n",
    "            \"spark.master\": \"local[*, 4]\",\n",
    "            \"spark.databricks.cluster.profile\": \"singleNode\"\n",
    "        },\n",
    "        \"node_type_id\": \"Standard_DS3_v2\"\n",
    "    },\n",
    "    \"notebook_task\": {\n",
    "        \"notebook_path\": \"/Users/pankaj.py2@outlook.com/Extract-Data-Task1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "create_job_response = requests.post(\n",
    "    f\"{databricks_url}/api/2.1/jobs/create\",\n",
    "    headers=headers,\n",
    "    json=job_payload\n",
    ")\n",
    "\n",
    "if create_job_response.status_code == 200:\n",
    "    job_id = create_job_response.json().get(\"job_id\")\n",
    "    print(f\"Job created with ID: {job_id}\")\n",
    "else:\n",
    "    print(f\"Failed to create job: {create_job_response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs in the workspace:\n",
      "Job ID: 561370898228136, Job Name: ETL-SQl-to-DL\n",
      "Job ID: 920062048610217, Job Name: MY-ETL-JOB\n",
      "Job ID: 513102915751090, Job Name: MyFirstJob3\n"
     ]
    }
   ],
   "source": [
    "# API endpoint for listing jobs\n",
    "list_jobs_url = f\"{databricks_url}/api/2.1/jobs/list\"\n",
    "\n",
    "# Make the API call\n",
    "response = requests.get(\n",
    "    list_jobs_url,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    jobs = response.json().get(\"jobs\", [])\n",
    "    if not jobs:\n",
    "        print(\"No jobs found in the workspace.\")\n",
    "    else:\n",
    "        print(\"Jobs in the workspace:\")\n",
    "        for job in jobs:\n",
    "            print(f\"Job ID: {job['job_id']}, Job Name: {job['settings']['name']}\")\n",
    "else:\n",
    "    print(f\"Error fetching jobs: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561370898228136"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job run initiated: {'run_id': 578636408087868, 'number_in_job': 578636408087868}\n"
     ]
    }
   ],
   "source": [
    "# Pass parameter to notebook\n",
    "parameters = {\n",
    "    \"file\" : \"new_file_name\"\n",
    "}\n",
    "\n",
    "# Trigger the job\n",
    "run_response = requests.post(\n",
    "    f\"{databricks_url}/api/2.1/jobs/run-now\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        \"job_id\": job_id,\n",
    "        \"notebook_params\" : parameters\n",
    "    }\n",
    ")\n",
    "\n",
    "output = run_response.json()\n",
    "print(f\"Job run initiated: {output}\")\n",
    "run_id = output.get(\"run_id\",\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Job Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Run Output:\n",
      "new_file_name\n"
     ]
    }
   ],
   "source": [
    "# Specify the run ID for which to get output\n",
    "run_id = \"578636408087868\"\n",
    "\n",
    "# API endpoint to get the job run output\n",
    "get_output_url = f\"{databricks_url}/api/2.1/jobs/runs/get-output\"\n",
    "\n",
    "# Make the API call\n",
    "response = requests.get(\n",
    "    get_output_url,\n",
    "    headers=headers,\n",
    "    params={\"run_id\": run_id}\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    output = response.json()\n",
    "    print(\"Job Run Output:\")\n",
    "    print(output.get(\"notebook_output\", {}).get(\"result\", \"No output available\"))\n",
    "else:\n",
    "    print(f\"Error fetching job output: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 578636408087868\n",
      "Lifecycle State: TERMINATED\n",
      "Result State: SUCCESS\n",
      "Run Page URL: https://adb-1420859118153884.4.azuredatabricks.net/?o=1420859118153884#job/561370898228136/run/578636408087868\n",
      "The job run was successful!\n"
     ]
    }
   ],
   "source": [
    "# Specify the run ID for which to get details\n",
    "run_id = \"578636408087868\"\n",
    "\n",
    "# API endpoint to get the job run details\n",
    "get_run_url = f\"{databricks_url}/api/2.1/jobs/runs/get\"\n",
    "\n",
    "# Make the API call\n",
    "response = requests.get(\n",
    "    get_run_url,\n",
    "    headers=headers,\n",
    "    params={\"run_id\": run_id}\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    run_details = response.json()\n",
    "    run_state = run_details.get(\"state\", {})\n",
    "    life_cycle_state = run_state.get(\"life_cycle_state\", \"Unknown\")\n",
    "    result_state = run_state.get(\"result_state\", \"Unknown\")\n",
    "    run_page_url = run_details.get(\"run_page_url\", \"N/A\")\n",
    "\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Lifecycle State: {life_cycle_state}\")\n",
    "    print(f\"Result State: {result_state}\")\n",
    "    print(f\"Run Page URL: {run_page_url}\")\n",
    "\n",
    "    if result_state == \"SUCCESS\":\n",
    "        print(\"The job run was successful!\")\n",
    "    elif result_state == \"FAILED\":\n",
    "        print(\"The job run failed.\")\n",
    "    else:\n",
    "        print(\"The job run is in progress or has an unknown status.\")\n",
    "else:\n",
    "    print(f\"Error fetching job details: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID 513102915751090 has been successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "# API endpoint to delete a job\n",
    "delete_job_url = f\"{databricks_url}/api/2.1/jobs/delete\"\n",
    "job_id = \"513102915751090\"\n",
    "\n",
    "# Make the API call\n",
    "response = requests.post(\n",
    "    delete_job_url,\n",
    "    headers=headers,\n",
    "    json={\"job_id\": job_id}\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    print(f\"Job ID {job_id} has been successfully deleted.\")\n",
    "else:\n",
    "    print(f\"Error deleting job: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Active Jobs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No jobs are currently running.\n"
     ]
    }
   ],
   "source": [
    "# API endpoint to list active job runs\n",
    "list_active_jobs_url = f\"{databricks_url}/api/2.1/jobs/runs/list\"\n",
    "\n",
    "# Fetch currently executing jobs\n",
    "params = {\n",
    "    \"active_only\": \"true\"  # Filter to include only active/running jobs\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "    list_active_jobs_url,\n",
    "    headers=headers,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Parse and display the response\n",
    "if response.status_code == 200:\n",
    "    active_jobs = response.json().get(\"runs\", [])\n",
    "    if not active_jobs:\n",
    "        print(\"No jobs are currently running.\")\n",
    "    else:\n",
    "        print(\"Currently Executing Jobs:\")\n",
    "        for job in active_jobs:\n",
    "            print(f\"Run ID: {job['run_id']}, Job ID: {job['job_id']}, Job Name: {job['run_name']}, State: {job['state']['life_cycle_state']}\")\n",
    "else:\n",
    "    print(f\"Error fetching executing jobs: {response.status_code} - {response.text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
